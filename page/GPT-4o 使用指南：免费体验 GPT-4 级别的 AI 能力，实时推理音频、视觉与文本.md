OpenAI 于 2024 年春季推出了 GPT-4o，这是一款全新的旗舰模型，能够实时处理音频、视觉和文本的推理任务。

> **提示**：想要成为 GPT-4o 的付费用户，可以使用邀请码 **ACCPAY** 享受开卡优惠！注册后可通过支付宝充值进行 ChatGPT 升级，或者直接使用 ChatGPT 随心体验，仅需手机号注册即可无障碍使用更多海外订阅服务。

## GPT-4o 的新特性

GPT-4o（“o”代表“omni”）标志着人机交互的重大进步。该模型支持文本、音频和图像的任意组合输入与输出。经过优化，音频响应时间可短至 232 毫秒，表现与人类相仿。

与 GPT-4 Turbo 相比，GPT-4o 在处理英语文本和代码上表现相当，但在非英语文本处理能力上有显著提升。同时，API 的处理速度比以往更快，成本也降低了 50%。在视觉和音频理解领域，GPT-4o 的表现尤为出色。

### 模型能力

在使用 GPT-4o 之前，用户通过语音模式与 ChatGPT 互动，平均延迟为 2.8 秒（GPT-3.5）和 5.4 秒（GPT-4）。语音模式的架构由三个独立模型组成，但可能导致信息损失，例如无法识别音调或背景噪音。而 GPT-4o 则采用了一体化的训练机制，使得输入输出都由同一神经网络处理，从而提高了整体表现。

### 模型评估

根据传统基准测试，GPT-4o 在文本推理和编码智能领域达到了 GPT-4 Turbo 的性能，且在多语言、音频及视觉功能的表现上设立了新的高标准。

- **文本评价**： GPT-4o 在 0-shot COT MMLU（常识问题）中得分高达 88.7%。
- **音频 ASR 性能**：GPT-4o 在语音识别方面比 Whisper-v3 有显著提升，尤其在资源不足的语言上表现更佳。
- **视觉理解评估**：使用 0-shot 的视觉评估，GPT-4o 在多项基准测试中超越了 GPT-4。

### 可用性

这一最新模型是 OpenAI 在深度学习领域的一次重要突破，旨在提升实用性。经过两年的努力，GPT-4o 现在能够更广泛地为用户提供 GPT-4 级别的智能。文本和图像功能已开始在 ChatGPT 中推出，并免费提供给用户。

### ChatGPT 免费用户可享功能

OpenAI 表示，ChatGPT 免费用户将能够体验 GPT-4o 的主要功能，包括：

- 使用 GPT-4 级别的智能
- 获取实时联网响应
- 数据分析和图表创建
- 照片讨论与分析
- 文件上传以提高总结与撰写效率
- 使用 GPTs 和 GPT Store
- 基于记忆的智能体验构建

### 免费向所有人提供 GPT-4 级别的 AI

这款新型 AI 模型将免费向所有用户开放 GPT-4 的级别能力。

现在，进入 ChatGPT 页面，Plus 用户将可优先体验这款“最新、最先进的模型”GPT-4o。无论是免费用户还是付费用户，都可以体验到 GPT-4 的强大功能。

尽管消息限制是免费用户的五倍，GPT-4o 在推理速度和多模态能力上具备更高的表现，允许同时理解文本、图像和音频等多种信息。

如果想要自由使用 GPT-4o 相关服务，立即查看 👉 [野卡 | 一分钟注册，轻松订阅海外线上服务](https://bit.ly/bewildcard)。

以上便是 OpenAI 春季发布会的全部内容。现在，GPT-4o 正式来临，OpenAI 再一次证明了他们在 AI 领域的领导地位。